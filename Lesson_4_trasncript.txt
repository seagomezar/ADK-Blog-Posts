0:04
By definition, agents are non-deterministic.
0:07
But that's not always the best
0:09
case scenario, especially if you're in production.
0:12
This lesson teaches you to build agents that behave somewhat predictably.
0:17
You'll do further instruction tuning
0:19
to optimize prompts and you'll use powerful callback systems
0:22
to programmatically enforce rules and create safety guardrails for production applications.
0:28
Let's get started. In the previous lessons,
0:31
we touched on the important topic of Instruction Tuning.
0:33
We started by providing our agent
0:35
a personality by defining its core identity.
0:38
then define its workflow and also give it a few rules
0:41
that scope down the user's request to
0:43
check if it was a valid request.
0:46
And only if it was a valid
0:47
request for AI news, it got passed.
0:49
And while these instructions guide the agent to steer the conversation
0:54
and reject requests that's like completely outside of its domain,
0:58
like maybe asking for a weather.
1:00
LLM is inherently non-deterministic.
1:03
And we wouldn't be able to guarantee execution
1:05
of any of those instructions every single time.
1:08
And this is actually a pretty serious problem
1:10
when it comes to a production system,
1:12
and this further amplifies in a live voice agent.
1:15
So in this lesson, you'll learn how to build agents
1:18
that go one step further than guide
1:20
and enforce callbacks at various
1:22
execution points of an agent.
1:25
So, what exactly is a callback?
1:27
They're actually Python functions that run at various
1:29
checkpoints of an agent's life cycle,
1:31
giving you programmatic control over agent behavior.
1:35
The various callback points in ADK are
1:37
before and after agent, before and after tool,
1:40
and before and after an LLM call.
1:42
Let's say for example, if you define
1:44
a Python function for a Before Model Callback
1:47
and add it to an agent, then that specific callback
1:50
which can be a deterministic piece of code will be executed
1:53
each time before an LLM call is made.
1:55
And these executions or life cycle points
1:58
in the agent can be a great place
2:00
to apply a set of generic functions that you want
2:04
to be executed for each agent tool or model.
2:07
Like say for example, you want to observe and debug the tools
2:11
and log detailed information or customizing and control the data
2:14
that is actually flowing between an agent and the sub agent,
2:17
and even enforce safety rules like checking the prompt for prompt injection
2:21
before passing it to an agent
2:23
or validating input and output and disallowing certain operations.
2:26
Okay, so it's great that we have the checkpoints, but
2:29
how exactly does the callback work?
2:31
Well, when ADK encounters a point where callback can actually run,
2:36
let's say for example, Just before a tool call,
2:38
it checks if you have provided
2:40
a corresponding callback function for that agent.
2:42
And if you did, the framework then calls that particular function.
2:46
And inside the callback function itself,
2:48
you have access to a special
2:50
object called the callback context or ToolContext.
2:52
Well, these objects contain vital information
2:55
about the current state of the agent's execution,
2:57
including the invocation details of which agent actually called it.
3:01
You can use these context objects
3:03
to understand the situation and interact with the framework.
3:06
And when the code execution is actually done within the callback,
3:10
you can return one of the two values from callbacks,
3:12
which would influence the agent's subsequent actions.
3:15
You can return the value none from
3:17
the callback, which will allow the agent
3:19
to actually continue its normal execution flow.
3:21
But if you return another object other than none,
3:24
this would override the default behavior of the agent.
3:27
Okay, let's now see this in action in
3:29
the next steps when we add a callback
3:31
to filter news sources for our podcast agent.
3:34
Let's create a new agent project structure.
3:36
using the ADK create command.
3:38
like usual, this just creates a folder structure
3:41
for our agent and sets up everything nicely.
3:43
And I'm going to go ahead and
3:45
start adding in code from our previous lessons
3:47
to our new app's agent.py.
3:50
Let's go ahead and copy paste the get_financial_context tool
3:54
and the save_news_to_markdown tools.
3:57
So here are the two tools we've built in our previous lessons.
4:00
I'm going to go ahead and run
4:02
this. There's no change in the code.
4:03
I'm just copy pasting it from
4:04
the previous lessons so we can continue.
4:06
building our agent on top of these.
4:08
With that, I'm going to go ahead and paste in
4:10
the small code that I have for our callback function.
4:12
And we're going to break this down
4:14
and explain in detail what's going on.
4:17
So just by looking at it, there
4:18
are a few different things to unpack here.
4:21
First, the definition of the function itself,
4:23
which takes in a few special arguments
4:25
like the tool, the args, and the tool_context.
4:28
And these arguments are actually very much
4:30
dependent on the type of the callback.
4:33
Since we'll be adding this callback as a before tool
4:36
callback to our agent,
4:38
it has access to these special tool arguments.
4:40
But if you were to add, let's say, an
4:43
after agent or before agent or a model callback,
4:45
you would have very different parameters than what you're seeing here.
4:48
Okay, let's go ahead and see what each of these arguments mean.
4:51
tool actually gives you the name of the tool
4:54
that interrupted or invoked this callback.
4:56
And args are the arguments that the LLM put together
4:59
to pass it to the actual tool, which then got interrupted.
5:03
And tool_context, like we saw earlier,
5:05
provides a tool access to certain external context
5:08
like session and state. So this specific callback actually looks at
5:12
our Google search tool
5:14
and then blocks few domains that we have defined here.
5:17
It demonstrates the programmatic policy enforcement.
5:21
So if you look at the
5:22
condition at the right at the top,
5:24
you see an if condition that narrows the callback down
5:27
to only execute if the tool is a Google search tool.
5:31
Meaning, if this callback was triggered by
5:35
the agent called the google_search tool
5:37
and then this callback interrupted it.
5:39
That's only time this will get executed.
5:41
And next, we look into the args
5:44
that got passed to the google_search tool itself,
5:46
and then fetch the query argument
5:48
to actually look if the query contains any
5:51
of the BLOCKED_DOMAINS that we have declared here.
5:54
We just have a random list of BLOCKED_DOMAINS here,
5:57
which may or may not be useful for our podcast.
5:59
Like for example, let's say we want to fetch latest AI news,
6:02
then we're not going to do it from archived information.
6:05
So we're just using few of the sites to block.
6:08
So based on the result of this if condition,
6:11
it will either return an error object
6:13
if the query is actually blocked, or it will return a None.
6:16
Notice also how the error messages are super descriptive
6:19
because this provides context to the agent
6:21
of why this query was actually blocked
6:24
and prevents any confusion that might arise later.
6:26
Okay, I'm going to go ahead run this cell for us
6:29
and we are going to add this specific callback to our agent.
6:32
And so far, we've seen how to actually
6:34
define a callback and block some domains.
6:37
But we're going to quickly do an after tool callback
6:40
before we add both of these to our agents.
6:42
I'm going to quickly copy a helper function
6:45
and then an actual callback here
6:47
and let's walk through the code together.
6:49
So this specific callback, which is inject_process_log_after_search,
6:53
it is basically a utility tool that we're using here
6:57
to log what sources of information that our agent actually used.
7:01
So let's say if it used a Google search to fetch
7:04
information from Reddit or from YouTube or anywhere, it's going to create
7:08
a log in our file that we
7:11
will be generating in a Markdown file.
7:13
So let's say if it used
7:15
Wikipedia or Reddit or YouTube or anything,
7:17
it's going to generate a log in the Markdown
7:19
file that we will be generating at the end.
7:22
So I'm going to go ahead and
7:24
add both these callbacks to our agent.
7:27
And this little helper function here
7:29
actually does nothing but writes the process_log to the tool
7:34
context using the state key.
7:36
So remember how we said that the
7:38
tool context actually has state information within it,
7:41
and this is exactly how you write information.
7:44
So basically, our callback lists all
7:46
the sources that the Google search tool
7:49
used to do the search, and then
7:50
it writes it to the state here,
7:52
using the tool_context.state function.
7:55
Okay, with that, let's now go ahead
7:57
and add both these callbacks to our agent.
8:00
Okay, let's break what this agent actually does.
8:04
If you scroll and then go to the bottom of this code,
8:06
you will see that we've now
8:08
added two of our callbacks right here.
8:10
The before_tool_callback, which actually runs before the tool is called,
8:15
and it makes sure that the
8:17
tool, in this case, the Google search,
8:19
doesn't use few sources of information or few domains.
8:22
And then the after_tool_callback, which runs after the tool,
8:26
basically when after the search is done,
8:29
and then logs all of the information and the sources which
8:33
the google_search tool actually used.
8:36
And let's say you have multiple callbacks
8:38
in the before and after tool callbacks.
8:41
Now, this would mean all of your callbacks would run
8:44
one by one in the sequence in which you defined.
8:47
And now, the next step is actually to update our agent's instructions
8:51
to provide it context about the
8:53
new callbacks that we added to it.
8:56
And these are all the instructions.
8:58
that are new to this callback. Let's break this down.
9:02
We provide our agent with situational awareness
9:05
saying you have a google_search tool
9:07
which is enhanced by pre- and post-processing callbacks.
9:11
And then we also tell it to write a process_log
9:14
of the sources which it used to do the search.
9:17
And we also have a small snippet here which then says
9:20
when it's testing callbacks, it asks our agent to be chatty
9:24
so it can actually explain you what's going on behind the scenes.
9:28
And this is all the new
9:30
code that we've added to our agent.
9:32
And now it's time to actually run
9:34
the agent and verify that our callbacks work.
9:36
Let's start up the terminal again and CD to the right folder.
9:40
I'm going to run the ADK web command again
9:43
to bring up our dev UI.
9:45
And we'll also run this small snippet
9:48
which should give us a proxy URL to access the web UI.
9:52
Can you give me the latest AI news? All done.
9:54
I've compiled the research report with the latest financial context
9:58
and saved it to AI_research_report.md
10:03
Can you tell me which sources you used to fetch this news?
10:06
The news was gathered from en.softbank,
10:08
blog.google, crescendo.ai,
10:11
indianexpress.com, and greenstocknews.com.
10:15
Well, can you fetch the AI news from Wikipedia or Reddit?
10:18
I am programmed only to use reputable news domains and avoid sources like wikipedia and reddit
10:23
Do you have a callback that prevents it?
10:25
Yes, that is correct. The callback system filters news sources to include only reputable domains.
10:30
This prevents fetching news from wikipedia or reddit.
10:33
Like we just saw, the agent actually uses the callback to
10:35
make a decision on which sources to fetch the information from.
10:37
Let's now go ahead to the report that the agent created
10:42
to actually verify the sources it used.
10:45
I'm going to paste in a small snippet
10:48
to display the markdown file it created.
10:52
Let's go ahead and run this and
10:54
here we see that the Process Log
10:57
from our after tool callback.
10:59
actually processed to include only sources that weren't actually blocked.
11:03
And that brings us to the end of this lesson.
11:05
You've built a production ready control system
11:08
combining instruction tuning and programmatic callbacks.
11:11
Your agent also now refuses off-topic requests consistently
11:15
and blocks certain domains to fetch information from.
11:18
In the next couple lessons, we'll expand beyond single agents
11:22
to build specialized agent teams that can work together
11:25
and actually give us the podcast episode.